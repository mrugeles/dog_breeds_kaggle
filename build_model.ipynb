{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "build model",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UydASg6F6FRK",
        "colab_type": "code",
        "outputId": "9c08db06-69b4-4d28-a36e-6628c0b93f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1210
        }
      },
      "source": [
        "!rm dogImages.zip\n",
        "!rm -rf dogImages\n",
        "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
        "!unzip -qq dogImages.zip\n",
        "!rm *.py\n",
        "!wget https://raw.githubusercontent.com/mrugeles/dog_breeds/master/data_utils.py\n",
        "!wget https://raw.githubusercontent.com/mrugeles/dog_breeds/master/model_utils.py\n",
        "!wget https://raw.githubusercontent.com/mrugeles/dog_breeds/master/model_stack.py\n",
        "!wget https://raw.githubusercontent.com/mrugeles/dog_breeds/master/build_model.py\n",
        "\n",
        "!mkdir app\n",
        "!rm *.npz\n",
        "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogXceptionData.npz\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'dogImages.zip': No such file or directory\n",
            "--2019-05-11 17:54:30--  https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
            "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.112.80\n",
            "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.112.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1132023110 (1.1G) [application/zip]\n",
            "Saving to: ‘dogImages.zip’\n",
            "\n",
            "dogImages.zip       100%[===================>]   1.05G  26.1MB/s    in 42s     \n",
            "\n",
            "2019-05-11 17:55:12 (26.0 MB/s) - ‘dogImages.zip’ saved [1132023110/1132023110]\n",
            "\n",
            "rm: cannot remove '*.py': No such file or directory\n",
            "--2019-05-11 17:55:27--  https://raw.githubusercontent.com/mrugeles/dog_breeds/master/data_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4201 (4.1K) [text/plain]\n",
            "Saving to: ‘data_utils.py’\n",
            "\n",
            "data_utils.py       100%[===================>]   4.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-05-11 17:55:27 (83.3 MB/s) - ‘data_utils.py’ saved [4201/4201]\n",
            "\n",
            "--2019-05-11 17:55:29--  https://raw.githubusercontent.com/mrugeles/dog_breeds/master/model_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5120 (5.0K) [text/plain]\n",
            "Saving to: ‘model_utils.py’\n",
            "\n",
            "model_utils.py      100%[===================>]   5.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-05-11 17:55:30 (75.5 MB/s) - ‘model_utils.py’ saved [5120/5120]\n",
            "\n",
            "--2019-05-11 17:55:32--  https://raw.githubusercontent.com/mrugeles/dog_breeds/master/model_stack.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3698 (3.6K) [text/plain]\n",
            "Saving to: ‘model_stack.py’\n",
            "\n",
            "model_stack.py      100%[===================>]   3.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-05-11 17:55:32 (90.4 MB/s) - ‘model_stack.py’ saved [3698/3698]\n",
            "\n",
            "--2019-05-11 17:55:34--  https://raw.githubusercontent.com/mrugeles/dog_breeds/master/build_model.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1584 (1.5K) [text/plain]\n",
            "Saving to: ‘build_model.py’\n",
            "\n",
            "build_model.py      100%[===================>]   1.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-05-11 17:55:34 (254 MB/s) - ‘build_model.py’ saved [1584/1584]\n",
            "\n",
            "rm: cannot remove '*.npz': No such file or directory\n",
            "--2019-05-11 17:55:40--  https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogXceptionData.npz\n",
            "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.116.33\n",
            "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.116.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3352158914 (3.1G) [application/x-www-form-urlencoded]\n",
            "Saving to: ‘DogXceptionData.npz’\n",
            "\n",
            "DogXceptionData.npz 100%[===================>]   3.12G  26.5MB/s    in 2m 1s   \n",
            "\n",
            "2019-05-11 17:57:42 (26.3 MB/s) - ‘DogXceptionData.npz’ saved [3352158914/3352158914]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xws2A6Q6c8_",
        "colab_type": "code",
        "outputId": "09b84542-3fb2-4472-d71f-d9398c2a6974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8894
        }
      },
      "source": [
        "import build_model\n",
        "build_model.main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Training Sub model 1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 6680 samples, validate on 835 samples\n",
            "Epoch 1/20\n",
            "6680/6680 [==============================] - 32s 5ms/step - loss: 1.3780 - acc: 0.6762 - val_loss: 0.8314 - val_acc: 0.7653\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.83142, saving model to weights.DogXceptionData_1.hdf5\n",
            "Epoch 2/20\n",
            "6680/6680 [==============================] - 27s 4ms/step - loss: 0.4113 - acc: 0.8744 - val_loss: 0.6930 - val_acc: 0.8000\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.83142 to 0.69304, saving model to weights.DogXceptionData_1.hdf5\n",
            "Epoch 3/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.2339 - acc: 0.9299 - val_loss: 0.5876 - val_acc: 0.8251\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.69304 to 0.58763, saving model to weights.DogXceptionData_1.hdf5\n",
            "Epoch 4/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.1358 - acc: 0.9612 - val_loss: 0.5315 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.58763 to 0.53145, saving model to weights.DogXceptionData_1.hdf5\n",
            "Epoch 5/20\n",
            "6680/6680 [==============================] - 27s 4ms/step - loss: 0.0851 - acc: 0.9795 - val_loss: 0.5347 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.53145\n",
            "Epoch 6/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0624 - acc: 0.9870 - val_loss: 0.5213 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.53145 to 0.52132, saving model to weights.DogXceptionData_1.hdf5\n",
            "Epoch 7/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0442 - acc: 0.9927 - val_loss: 0.5086 - val_acc: 0.8563\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.52132 to 0.50855, saving model to weights.DogXceptionData_1.hdf5\n",
            "Epoch 8/20\n",
            "6680/6680 [==============================] - 27s 4ms/step - loss: 0.0347 - acc: 0.9937 - val_loss: 0.5713 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.50855\n",
            "Epoch 9/20\n",
            "6680/6680 [==============================] - 27s 4ms/step - loss: 0.0282 - acc: 0.9960 - val_loss: 0.5396 - val_acc: 0.8479\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.50855\n",
            "Epoch 10/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0207 - acc: 0.9976 - val_loss: 0.5448 - val_acc: 0.8563\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.50855\n",
            "Epoch 11/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0211 - acc: 0.9963 - val_loss: 0.5216 - val_acc: 0.8599\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.50855\n",
            "Epoch 12/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0205 - acc: 0.9966 - val_loss: 0.5582 - val_acc: 0.8575\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.50855\n",
            "Epoch 13/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0195 - acc: 0.9969 - val_loss: 0.5558 - val_acc: 0.8575\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.50855\n",
            "Epoch 14/20\n",
            "6680/6680 [==============================] - 27s 4ms/step - loss: 0.0155 - acc: 0.9975 - val_loss: 0.5190 - val_acc: 0.8575\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.50855\n",
            "Epoch 15/20\n",
            "6680/6680 [==============================] - 27s 4ms/step - loss: 0.0165 - acc: 0.9976 - val_loss: 0.5177 - val_acc: 0.8635\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.50855\n",
            "Epoch 16/20\n",
            "6680/6680 [==============================] - 27s 4ms/step - loss: 0.0151 - acc: 0.9975 - val_loss: 0.5204 - val_acc: 0.8635\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.50855\n",
            "Epoch 17/20\n",
            "6680/6680 [==============================] - 27s 4ms/step - loss: 0.0138 - acc: 0.9972 - val_loss: 0.5373 - val_acc: 0.8623\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.50855\n",
            "Epoch 18/20\n",
            "6680/6680 [==============================] - 27s 4ms/step - loss: 0.0117 - acc: 0.9979 - val_loss: 0.5890 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.50855\n",
            "Epoch 19/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0110 - acc: 0.9987 - val_loss: 0.5570 - val_acc: 0.8575\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.50855\n",
            "Epoch 20/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0111 - acc: 0.9981 - val_loss: 0.5623 - val_acc: 0.8659\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.50855\n",
            "Sub model DogXceptionData 1 accuracy: 85.5263%\n",
            "Training time: 9.5108% minutes\n",
            "\n",
            "Training Sub model 2\n",
            "Train on 6680 samples, validate on 835 samples\n",
            "Epoch 1/20\n",
            "6680/6680 [==============================] - 29s 4ms/step - loss: 1.3593 - acc: 0.6740 - val_loss: 0.7760 - val_acc: 0.7784\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.77598, saving model to weights.DogXceptionData_2.hdf5\n",
            "Epoch 2/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.3999 - acc: 0.8757 - val_loss: 0.6352 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.77598 to 0.63522, saving model to weights.DogXceptionData_2.hdf5\n",
            "Epoch 3/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.2208 - acc: 0.9325 - val_loss: 0.5767 - val_acc: 0.8311\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.63522 to 0.57668, saving model to weights.DogXceptionData_2.hdf5\n",
            "Epoch 4/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.1364 - acc: 0.9602 - val_loss: 0.6082 - val_acc: 0.8323\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.57668\n",
            "Epoch 5/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0875 - acc: 0.9792 - val_loss: 0.5180 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.57668 to 0.51801, saving model to weights.DogXceptionData_2.hdf5\n",
            "Epoch 6/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0626 - acc: 0.9865 - val_loss: 0.5394 - val_acc: 0.8431\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.51801\n",
            "Epoch 7/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0425 - acc: 0.9913 - val_loss: 0.5356 - val_acc: 0.8359\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.51801\n",
            "Epoch 8/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0322 - acc: 0.9942 - val_loss: 0.5265 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.51801\n",
            "Epoch 9/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0298 - acc: 0.9948 - val_loss: 0.5416 - val_acc: 0.8551\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.51801\n",
            "Epoch 10/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0230 - acc: 0.9969 - val_loss: 0.5570 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.51801\n",
            "Epoch 11/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0225 - acc: 0.9967 - val_loss: 0.5425 - val_acc: 0.8455\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.51801\n",
            "Epoch 12/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0198 - acc: 0.9963 - val_loss: 0.5607 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.51801\n",
            "Epoch 13/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0162 - acc: 0.9976 - val_loss: 0.5843 - val_acc: 0.8479\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.51801\n",
            "Epoch 14/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0150 - acc: 0.9973 - val_loss: 0.5522 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.51801\n",
            "Epoch 15/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0128 - acc: 0.9984 - val_loss: 0.6181 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.51801\n",
            "Epoch 16/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0144 - acc: 0.9975 - val_loss: 0.5982 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.51801\n",
            "Epoch 17/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0167 - acc: 0.9969 - val_loss: 0.5785 - val_acc: 0.8479\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.51801\n",
            "Epoch 18/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0125 - acc: 0.9979 - val_loss: 0.5699 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.51801\n",
            "Epoch 19/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0117 - acc: 0.9984 - val_loss: 0.5943 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.51801\n",
            "Epoch 20/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0104 - acc: 0.9976 - val_loss: 0.5807 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.51801\n",
            "Sub model DogXceptionData 2 accuracy: 84.6890%\n",
            "Training time: 9.7890% minutes\n",
            "\n",
            "Training Sub model 3\n",
            "Train on 6680 samples, validate on 835 samples\n",
            "Epoch 1/20\n",
            "6680/6680 [==============================] - 29s 4ms/step - loss: 1.3137 - acc: 0.6786 - val_loss: 0.7475 - val_acc: 0.7868\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.74747, saving model to weights.DogXceptionData_3.hdf5\n",
            "Epoch 2/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.3992 - acc: 0.8795 - val_loss: 0.6399 - val_acc: 0.8036\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.74747 to 0.63987, saving model to weights.DogXceptionData_3.hdf5\n",
            "Epoch 3/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.2264 - acc: 0.9317 - val_loss: 0.6915 - val_acc: 0.8024\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.63987\n",
            "Epoch 4/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.1356 - acc: 0.9593 - val_loss: 0.5912 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.63987 to 0.59116, saving model to weights.DogXceptionData_3.hdf5\n",
            "Epoch 5/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0843 - acc: 0.9786 - val_loss: 0.5555 - val_acc: 0.8240\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.59116 to 0.55549, saving model to weights.DogXceptionData_3.hdf5\n",
            "Epoch 6/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0557 - acc: 0.9892 - val_loss: 0.5703 - val_acc: 0.8443\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.55549\n",
            "Epoch 7/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0432 - acc: 0.9919 - val_loss: 0.5742 - val_acc: 0.8323\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.55549\n",
            "Epoch 8/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0347 - acc: 0.9939 - val_loss: 0.5380 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.55549 to 0.53801, saving model to weights.DogXceptionData_3.hdf5\n",
            "Epoch 9/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0286 - acc: 0.9943 - val_loss: 0.5591 - val_acc: 0.8455\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.53801\n",
            "Epoch 10/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0231 - acc: 0.9967 - val_loss: 0.5343 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.53801 to 0.53430, saving model to weights.DogXceptionData_3.hdf5\n",
            "Epoch 11/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0225 - acc: 0.9954 - val_loss: 0.5543 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.53430\n",
            "Epoch 12/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0174 - acc: 0.9970 - val_loss: 0.5361 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.53430\n",
            "Epoch 13/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0152 - acc: 0.9973 - val_loss: 0.5571 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.53430\n",
            "Epoch 14/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0154 - acc: 0.9976 - val_loss: 0.5546 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.53430\n",
            "Epoch 15/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0180 - acc: 0.9958 - val_loss: 0.5475 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.53430\n",
            "Epoch 16/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0140 - acc: 0.9979 - val_loss: 0.5679 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.53430\n",
            "Epoch 17/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0131 - acc: 0.9982 - val_loss: 0.5717 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.53430\n",
            "Epoch 18/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0138 - acc: 0.9975 - val_loss: 0.5892 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.53430\n",
            "Epoch 19/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0121 - acc: 0.9972 - val_loss: 0.5617 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.53430\n",
            "Epoch 20/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0117 - acc: 0.9979 - val_loss: 0.5837 - val_acc: 0.8563\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.53430\n",
            "Sub model DogXceptionData 3 accuracy: 85.0478%\n",
            "Training time: 9.7998% minutes\n",
            "\n",
            "Training Sub model 4\n",
            "Train on 6680 samples, validate on 835 samples\n",
            "Epoch 1/20\n",
            "6680/6680 [==============================] - 29s 4ms/step - loss: 1.3059 - acc: 0.6820 - val_loss: 0.7475 - val_acc: 0.7988\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.74748, saving model to weights.DogXceptionData_4.hdf5\n",
            "Epoch 2/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.4015 - acc: 0.8754 - val_loss: 0.5643 - val_acc: 0.8323\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.74748 to 0.56435, saving model to weights.DogXceptionData_4.hdf5\n",
            "Epoch 3/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.2276 - acc: 0.9305 - val_loss: 0.5371 - val_acc: 0.8431\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.56435 to 0.53714, saving model to weights.DogXceptionData_4.hdf5\n",
            "Epoch 4/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.1399 - acc: 0.9608 - val_loss: 0.5005 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.53714 to 0.50053, saving model to weights.DogXceptionData_4.hdf5\n",
            "Epoch 5/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0807 - acc: 0.9808 - val_loss: 0.5297 - val_acc: 0.8371\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.50053\n",
            "Epoch 6/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0601 - acc: 0.9873 - val_loss: 0.5348 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.50053\n",
            "Epoch 7/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0446 - acc: 0.9904 - val_loss: 0.5432 - val_acc: 0.8479\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.50053\n",
            "Epoch 8/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0338 - acc: 0.9948 - val_loss: 0.5161 - val_acc: 0.8479\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.50053\n",
            "Epoch 9/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0259 - acc: 0.9963 - val_loss: 0.5057 - val_acc: 0.8551\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.50053\n",
            "Epoch 10/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0217 - acc: 0.9966 - val_loss: 0.5517 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.50053\n",
            "Epoch 11/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0211 - acc: 0.9964 - val_loss: 0.5303 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.50053\n",
            "Epoch 12/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0181 - acc: 0.9973 - val_loss: 0.5419 - val_acc: 0.8623\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.50053\n",
            "Epoch 13/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0181 - acc: 0.9964 - val_loss: 0.5574 - val_acc: 0.8551\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.50053\n",
            "Epoch 14/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0146 - acc: 0.9981 - val_loss: 0.5226 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.50053\n",
            "Epoch 15/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0149 - acc: 0.9976 - val_loss: 0.5340 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.50053\n",
            "Epoch 16/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0145 - acc: 0.9972 - val_loss: 0.5644 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.50053\n",
            "Epoch 17/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0142 - acc: 0.9973 - val_loss: 0.5463 - val_acc: 0.8575\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.50053\n",
            "Epoch 18/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0137 - acc: 0.9978 - val_loss: 0.5538 - val_acc: 0.8551\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.50053\n",
            "Epoch 19/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0127 - acc: 0.9981 - val_loss: 0.5817 - val_acc: 0.8563\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.50053\n",
            "Epoch 20/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0101 - acc: 0.9982 - val_loss: 0.5352 - val_acc: 0.8659\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.50053\n",
            "Sub model DogXceptionData 4 accuracy: 84.0909%\n",
            "Training time: 9.7314% minutes\n",
            "\n",
            "Training Sub model 5\n",
            "Train on 6680 samples, validate on 835 samples\n",
            "Epoch 1/20\n",
            "6680/6680 [==============================] - 29s 4ms/step - loss: 1.3267 - acc: 0.6753 - val_loss: 0.7847 - val_acc: 0.7665\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.78471, saving model to weights.DogXceptionData_5.hdf5\n",
            "Epoch 2/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.4055 - acc: 0.8781 - val_loss: 0.6277 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.78471 to 0.62769, saving model to weights.DogXceptionData_5.hdf5\n",
            "Epoch 3/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.2209 - acc: 0.9337 - val_loss: 0.5639 - val_acc: 0.8383\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.62769 to 0.56387, saving model to weights.DogXceptionData_5.hdf5\n",
            "Epoch 4/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.1314 - acc: 0.9611 - val_loss: 0.5481 - val_acc: 0.8479\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.56387 to 0.54809, saving model to weights.DogXceptionData_5.hdf5\n",
            "Epoch 5/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0829 - acc: 0.9810 - val_loss: 0.5059 - val_acc: 0.8551\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.54809 to 0.50587, saving model to weights.DogXceptionData_5.hdf5\n",
            "Epoch 6/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0603 - acc: 0.9858 - val_loss: 0.4990 - val_acc: 0.8443\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.50587 to 0.49895, saving model to weights.DogXceptionData_5.hdf5\n",
            "Epoch 7/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0457 - acc: 0.9909 - val_loss: 0.4757 - val_acc: 0.8671\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.49895 to 0.47573, saving model to weights.DogXceptionData_5.hdf5\n",
            "Epoch 8/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0316 - acc: 0.9952 - val_loss: 0.5268 - val_acc: 0.8671\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.47573\n",
            "Epoch 9/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0289 - acc: 0.9943 - val_loss: 0.5007 - val_acc: 0.8683\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.47573\n",
            "Epoch 10/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0251 - acc: 0.9957 - val_loss: 0.5218 - val_acc: 0.8659\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.47573\n",
            "Epoch 11/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0203 - acc: 0.9967 - val_loss: 0.5156 - val_acc: 0.8743\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.47573\n",
            "Epoch 12/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0173 - acc: 0.9972 - val_loss: 0.5108 - val_acc: 0.8719\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.47573\n",
            "Epoch 13/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0152 - acc: 0.9976 - val_loss: 0.5310 - val_acc: 0.8659\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.47573\n",
            "Epoch 14/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0135 - acc: 0.9979 - val_loss: 0.5525 - val_acc: 0.8683\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.47573\n",
            "Epoch 15/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0161 - acc: 0.9966 - val_loss: 0.5511 - val_acc: 0.8707\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.47573\n",
            "Epoch 16/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0144 - acc: 0.9976 - val_loss: 0.5292 - val_acc: 0.8647\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.47573\n",
            "Epoch 17/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0136 - acc: 0.9978 - val_loss: 0.7518 - val_acc: 0.8431\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.47573\n",
            "Epoch 18/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0188 - acc: 0.9966 - val_loss: 0.5195 - val_acc: 0.8719\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.47573\n",
            "Epoch 19/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0113 - acc: 0.9982 - val_loss: 0.5598 - val_acc: 0.8647\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.47573\n",
            "Epoch 20/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0120 - acc: 0.9979 - val_loss: 0.5294 - val_acc: 0.8623\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.47573\n",
            "Sub model DogXceptionData 5 accuracy: 84.5694%\n",
            "Training time: 9.5723% minutes\n",
            "\n",
            "Training Sub model 6\n",
            "Train on 6680 samples, validate on 835 samples\n",
            "Epoch 1/20\n",
            "6680/6680 [==============================] - 29s 4ms/step - loss: 1.3118 - acc: 0.6769 - val_loss: 0.8199 - val_acc: 0.7653\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.81992, saving model to weights.DogXceptionData_6.hdf5\n",
            "Epoch 2/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.3990 - acc: 0.8793 - val_loss: 0.5528 - val_acc: 0.8299\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.81992 to 0.55278, saving model to weights.DogXceptionData_6.hdf5\n",
            "Epoch 3/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.2208 - acc: 0.9325 - val_loss: 0.5898 - val_acc: 0.8072\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.55278\n",
            "Epoch 4/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.1311 - acc: 0.9638 - val_loss: 0.5419 - val_acc: 0.8359\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.55278 to 0.54193, saving model to weights.DogXceptionData_6.hdf5\n",
            "Epoch 5/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0836 - acc: 0.9804 - val_loss: 0.5197 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.54193 to 0.51973, saving model to weights.DogXceptionData_6.hdf5\n",
            "Epoch 6/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0605 - acc: 0.9867 - val_loss: 0.5615 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.51973\n",
            "Epoch 7/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0423 - acc: 0.9930 - val_loss: 0.5132 - val_acc: 0.8575\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.51973 to 0.51316, saving model to weights.DogXceptionData_6.hdf5\n",
            "Epoch 8/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0333 - acc: 0.9949 - val_loss: 0.5210 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.51316\n",
            "Epoch 9/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0279 - acc: 0.9954 - val_loss: 0.5174 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.51316\n",
            "Epoch 10/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0239 - acc: 0.9958 - val_loss: 0.5406 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.51316\n",
            "Epoch 11/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0273 - acc: 0.9949 - val_loss: 0.5684 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.51316\n",
            "Epoch 12/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0192 - acc: 0.9957 - val_loss: 0.5362 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.51316\n",
            "Epoch 13/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0160 - acc: 0.9978 - val_loss: 0.5462 - val_acc: 0.8587\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.51316\n",
            "Epoch 14/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0138 - acc: 0.9982 - val_loss: 0.5468 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.51316\n",
            "Epoch 15/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0151 - acc: 0.9972 - val_loss: 0.5380 - val_acc: 0.8575\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.51316\n",
            "Epoch 16/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0150 - acc: 0.9972 - val_loss: 0.5435 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.51316\n",
            "Epoch 17/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0139 - acc: 0.9969 - val_loss: 0.5618 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.51316\n",
            "Epoch 18/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0120 - acc: 0.9978 - val_loss: 0.5451 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.51316\n",
            "Epoch 19/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0109 - acc: 0.9985 - val_loss: 0.5512 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.51316\n",
            "Epoch 20/20\n",
            "6680/6680 [==============================] - 28s 4ms/step - loss: 0.0098 - acc: 0.9981 - val_loss: 0.5487 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.51316\n",
            "Sub model DogXceptionData 6 accuracy: 85.2871%\n",
            "Training time: 9.5542% minutes\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}